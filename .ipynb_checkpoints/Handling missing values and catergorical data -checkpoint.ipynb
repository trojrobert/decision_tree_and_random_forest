{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the file to read\n",
    "iowa_file_path = 'housing_price_iowa.csv'\n",
    "#import the data\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "target_y = home_data.SalePrice\n",
    "#print(target_y)\n",
    "\n",
    "#get all other column excpet the target column  \n",
    "features_X = home_data.drop(['SalePrice'], axis=1)\n",
    "#print(features_X)\n",
    "\n",
    "\n",
    "def calculate_MAE(train_X, val_X, train_y, val_y):\n",
    "    # Define the model\n",
    "    rf_model = RandomForestRegressor()\n",
    "\n",
    "    # fit your model\n",
    "    rf_model.fit(train_X, train_y)\n",
    "    #make predictions\n",
    "    rf_predictions = rf_model.predict(val_X)\n",
    "    # Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "    rf_val_mae = mean_absolute_error(val_y,rf_predictions)\n",
    "    \n",
    "    return rf_val_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways of Handling missing/nan values \n",
    "\n",
    "### Drop columns with NAN values(missing values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_values(train_X, val_X, train_y, val_y):\n",
    "    #get the column with nan values \n",
    "    cols_with_nan = [col for col in train_X.columns if train_X[col].isnull().any()]\n",
    "\n",
    "    #drop the columns with nan values\n",
    "    print(cols_with_nan)\n",
    "    modified_train_X = train_X.drop(cols_with_nan, axis=1)\n",
    "    modified_val_X = val_X.drop(cols_with_nan, axis=1)\n",
    "\n",
    "    drop_nan_MAE=calculate_MAE(modified_train_X, modified_val_X, train_y, val_y)\n",
    "    return drop_nan_MAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation - fills in the missing value with some number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "def impute_values(train_X, val_X, train_y, val_y):\n",
    "\n",
    "    my_imputer = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    #my_imputer = SimpleImputer()\n",
    "\n",
    "    #Impute values \n",
    "    imputed_train_X = my_imputer.fit_transform(train_X)\n",
    "    imputed_val_X = my_imputer.fit_transform(val_X)\n",
    "\n",
    "    impute_MAE=calculate_MAE(imputed_train_X, imputed_val_X, train_y, val_y)\n",
    "    return impute_MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation with Extra Columns Showing What Was Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_impute_values(train_X, val_X, train_y, val_y):\n",
    "    new_imputed_train_X = train_X.copy()\n",
    "    new_imputed_val_X = val_X.copy()\n",
    "\n",
    "    for col in cols_with_nan:\n",
    "        new_imputed_train_X[col + 'missing'] = new_imputed_train_X[col].isnull()\n",
    "        new_imputed_val_X[col + 'missing'] = new_imputed_val_X[col].isnull()\n",
    "\n",
    "    new_imputed_train_X = my_imputer.fit_transform(new_imputed_train_X)\n",
    "    new_imputed_val_X = my_imputer.fit_transform(new_imputed_val_X)\n",
    "\n",
    "    new_impute_MAE=calculate_MAE(new_imputed_train_X, new_imputed_val_X, train_y, val_y)\n",
    "    \n",
    "    return new_impute_MAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling catergorical data that is column with object type (not float values)\n",
    "\n",
    "### Drop columns with object type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "MAE from dropping columns with Missing Values is 17720.05506849315\n",
      "MAE from Imputation is 18286.271232876712\n",
      "MAE from Imputation while Track What Was Imputed is 18544.07123287671\n"
     ]
    }
   ],
   "source": [
    "#print(features_X.dtypes)\n",
    "\n",
    "#Remove columns that are non float from the features\n",
    "drop_catergorical_X = features_X.select_dtypes(exclude=['object'])\n",
    "#Split the data to train and text set \n",
    "train_X, val_X, train_y, val_y = train_test_split(drop_catergorical_X, target_y, random_state = 1)\n",
    "\n",
    "drop_nan_MAE = drop_nan_values(train_X, val_X, train_y, val_y)\n",
    "impute_MAE = impute_values(train_X, val_X, train_y, val_y)\n",
    "extended_impute_MAE = extended_impute_values(train_X, val_X, train_y, val_y)\n",
    "\n",
    "print(\"MAE from dropping columns with Missing Values is {}\".format(drop_nan_MAE))\n",
    "print(\"MAE from Imputation is {}\".format(impute_MAE))\n",
    "print(\"MAE from Imputation while Track What Was Imputed is {}\".format(extended_impute_MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding : The Standard Approach for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "Using One hot encoder MAE from dropping columns with Missing Values is 17641.221369863015\n",
      "Using One hot encoder  MAE from Imputation is 17974.474520547945\n",
      "Using One hot encoder MAE from Imputation while Track What Was Imputed is 18490.50383561644\n"
     ]
    }
   ],
   "source": [
    "#Handling non float columns with one-hot-encoding\n",
    "one_hot_features_X = pd.get_dummies(features_X)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(one_hot_features_X, target_y, random_state = 1)\n",
    "\n",
    " \n",
    "#one_hot_train_X = pd.get_dummies(train_X)\n",
    "#one_hot_val_X = pd.get_dummies(val_X)\n",
    "\n",
    "drop_nan_MAE = drop_nan_values(train_X, val_X, train_y, val_y)\n",
    "impute_MAE = impute_values(train_X, val_X, train_y, val_y)\n",
    "extended_impute_MAE = extended_impute_values(train_X, val_X, train_y, val_y)\n",
    "\n",
    "print(\"Using One hot encoder MAE from dropping columns with Missing Values is {}\".format(drop_nan_MAE))\n",
    "print(\"Using One hot encoder  MAE from Imputation is {}\".format(impute_MAE))\n",
    "print(\"Using One hot encoder MAE from Imputation while Track What Was Imputed is {}\".format(extended_impute_MAE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
